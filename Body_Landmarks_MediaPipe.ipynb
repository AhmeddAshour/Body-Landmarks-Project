{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "05pmvwbv2CHz",
        "outputId": "b18fca2d-0611-4dba-ec33-fa59b3d7e24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.20 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5pFeTuVJ24uy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MediaPipe components globally for holistic model and drawing utilities\n",
        "mp_holistic = mp.solutions.holistic  # MediaPipe Holistic for full-body landmark detection\n",
        "mp_drawing = mp.solutions.drawing_utils  # Utility to draw landmarks and connections"
      ],
      "metadata": {
        "id": "2pTvDJ_R7pRq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_video(video_path):\n",
        "    \"\"\"\n",
        "    Initialize video capture, output settings, and check video properties.\n",
        "    Args:\n",
        "        video_path (str): Path to the input video file.\n",
        "    Returns:\n",
        "        cap: VideoCapture object for reading video frames.\n",
        "        out: VideoWriter object to save processed video.\n",
        "        frame_width (int): Width of the video frames.\n",
        "        frame_height (int): Height of the video frames.\n",
        "        fps (int): Frames per second of the input video.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)  # Capture video from the file\n",
        "    if not cap.isOpened():  # Check if video file is loaded successfully\n",
        "        print(\"Error: Could not open video file.\")\n",
        "        exit()\n",
        "\n",
        "    # Extract video properties\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Set up output video file properties\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 format\n",
        "    out = cv2.VideoWriter('Body_Landmarks.mp4', fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    return cap, out, frame_width, frame_height, fps"
      ],
      "metadata": {
        "id": "q5UltwRo7sxB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_dense_connections():\n",
        "    \"\"\"\n",
        "    Define the dense connections between body landmarks for enhanced visualization.\n",
        "    Returns:\n",
        "        list of tuples: Dense landmark connections for drawing lines between key points.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Dense body connections between shoulders, elbows, wrists, hips, knees, and ankles\n",
        "        (mp_holistic.PoseLandmark.LEFT_SHOULDER.value, mp_holistic.PoseLandmark.RIGHT_SHOULDER.value),\n",
        "        (mp_holistic.PoseLandmark.LEFT_SHOULDER.value, mp_holistic.PoseLandmark.LEFT_ELBOW.value),\n",
        "        (mp_holistic.PoseLandmark.LEFT_ELBOW.value, mp_holistic.PoseLandmark.LEFT_WRIST.value),\n",
        "        (mp_holistic.PoseLandmark.RIGHT_SHOULDER.value, mp_holistic.PoseLandmark.RIGHT_ELBOW.value),\n",
        "        (mp_holistic.PoseLandmark.RIGHT_ELBOW.value, mp_holistic.PoseLandmark.RIGHT_WRIST.value),\n",
        "        (mp_holistic.PoseLandmark.LEFT_HIP.value, mp_holistic.PoseLandmark.RIGHT_HIP.value),\n",
        "        (mp_holistic.PoseLandmark.LEFT_HIP.value, mp_holistic.PoseLandmark.LEFT_KNEE.value),\n",
        "        (mp_holistic.PoseLandmark.LEFT_KNEE.value, mp_holistic.PoseLandmark.LEFT_ANKLE.value),\n",
        "        (mp_holistic.PoseLandmark.RIGHT_HIP.value, mp_holistic.PoseLandmark.RIGHT_KNEE.value),\n",
        "        (mp_holistic.PoseLandmark.RIGHT_KNEE.value, mp_holistic.PoseLandmark.RIGHT_ANKLE.value),\n",
        "        (mp_holistic.PoseLandmark.LEFT_SHOULDER.value, mp_holistic.PoseLandmark.LEFT_HIP.value),\n",
        "        (mp_holistic.PoseLandmark.RIGHT_SHOULDER.value, mp_holistic.PoseLandmark.RIGHT_HIP.value),\n",
        "    ]"
      ],
      "metadata": {
        "id": "GxdFcflo7uvW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_frame(frame, holistic, dense_body_connections, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    Process a single video frame to detect landmarks and draw visualizations.\n",
        "    Args:\n",
        "        frame: The input frame.\n",
        "        holistic: MediaPipe Holistic model object.\n",
        "        dense_body_connections (list): List of landmark connections to draw.\n",
        "        frame_width (int): Width of the frame.\n",
        "        frame_height (int): Height of the frame.\n",
        "    Returns:\n",
        "        black_frame: A black frame with the detected landmarks and connections drawn.\n",
        "    \"\"\"\n",
        "    # Create a black canvas of the same size as the input frame\n",
        "    black_frame = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
        "\n",
        "    # Convert the BGR image to RGB (required for MediaPipe processing)\n",
        "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = holistic.process(imgRGB)  # Process the frame to detect landmarks\n",
        "\n",
        "    # Draw body landmarks\n",
        "    if results.pose_landmarks:\n",
        "        draw_dense_body_connections(black_frame, results, dense_body_connections, frame_width, frame_height)\n",
        "        draw_body_landmark_points(black_frame, results, frame_width, frame_height)\n",
        "\n",
        "    # Draw hands and face landmarks\n",
        "    draw_hands_and_face(black_frame, results)\n",
        "\n",
        "    return black_frame"
      ],
      "metadata": {
        "id": "sCQyBPZx7xFB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_dense_body_connections(black_frame, results, dense_body_connections, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    Draw dense lines connecting body landmarks.\n",
        "    \"\"\"\n",
        "    for connection in dense_body_connections:\n",
        "        start_idx, end_idx = connection\n",
        "        start = results.pose_landmarks.landmark[start_idx]\n",
        "        end = results.pose_landmarks.landmark[end_idx]\n",
        "        start_point = (int(start.x * frame_width), int(start.y * frame_height))\n",
        "        end_point = (int(end.x * frame_width), int(end.y * frame_height))\n",
        "        cv2.line(black_frame, start_point, end_point, (255, 255, 0), thickness=2)"
      ],
      "metadata": {
        "id": "QS7Lkgz_7zQi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_body_landmark_points(black_frame, results, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    Draw small circles on each body landmark.\n",
        "    \"\"\"\n",
        "    for landmark in results.pose_landmarks.landmark:\n",
        "        x = int(landmark.x * frame_width)\n",
        "        y = int(landmark.y * frame_height)\n",
        "        cv2.circle(black_frame, (x, y), radius=3, color=(0, 255, 255), thickness=-1)"
      ],
      "metadata": {
        "id": "ve1iUVEz71d8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_hands_and_face(black_frame, results):\n",
        "    \"\"\"\n",
        "    Draw hands and face landmarks using MediaPipe drawing utilities.\n",
        "    \"\"\"\n",
        "    if results.left_hand_landmarks:\n",
        "        mp_drawing.draw_landmarks(\n",
        "            black_frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
        "        )\n",
        "    if results.right_hand_landmarks:\n",
        "        mp_drawing.draw_landmarks(\n",
        "            black_frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "            mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2)\n",
        "        )\n",
        "    if results.face_landmarks:\n",
        "        mp_drawing.draw_landmarks(\n",
        "            black_frame, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
        "            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=1, circle_radius=1)\n",
        "        )"
      ],
      "metadata": {
        "id": "tX-U-x5f73p6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(video_path):\n",
        "    \"\"\"\n",
        "    Main function to read video, process frames, and save the output video.\n",
        "    Args:\n",
        "        video_path (str): Path to the input video file.\n",
        "    \"\"\"\n",
        "    # Initialize video capture, output, and MediaPipe holistic model\n",
        "    cap, out, frame_width, frame_height, fps = initialize_video(video_path)\n",
        "    holistic = mp_holistic.Holistic()\n",
        "    dense_body_connections = define_dense_connections()\n",
        "    pTime = 0  # Initialize previous time for FPS calculation\n",
        "\n",
        "    while True:\n",
        "        success, frame = cap.read()\n",
        "        if not success:  # End of video\n",
        "            print(\"End of video file.\")\n",
        "            break\n",
        "\n",
        "        # Process the frame to detect landmarks\n",
        "        black_frame = process_frame(frame, holistic, dense_body_connections, frame_width, frame_height)\n",
        "\n",
        "        # Calculate and display FPS\n",
        "        cTime = time.time()\n",
        "        fps_text = 1 / (cTime - pTime)\n",
        "        pTime = cTime\n",
        "        cv2.putText(black_frame, f\"FPS= {int(fps_text)}\", (10, 20), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n",
        "\n",
        "        # Write the processed frame to the output video file\n",
        "        # out.write(black_frame)\n",
        "\n",
        "        # Display the frame in Colab (optional)\n",
        "        # cv2_imshow(black_frame)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Video processing complete. Output saved to 'Body_Landmarks.mp4'\")\n",
        "\n",
        "# Run the main function with the input video path\n",
        "video_path = \"/content/Raw_Video.mp4\"\n",
        "main(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF9hseKV75lJ",
        "outputId": "af9299e6-a1b3-4be5-e7d0-1ffd9baf9edb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of video file.\n",
            "Video processing complete. Output saved to 'Body_Landmarks.mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function\n",
        "video_path = \"/content/Raw_Video.mp4\"\n",
        "main(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3fk6ids78nN",
        "outputId": "9372577c-7073-4488-945d-b4fbc357ba61"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of video file.\n",
            "Video processing complete. Output saved to 'Body_Landmarks.mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/Body_Landmarks.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yXj2t8Wt8NRC",
        "outputId": "83e4c005-b442-402d-a795-80a89e5bb7bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a94cb0a3-77f6-45ee-88f4-e7580a9bae7c\", \"Enhanced_Body_Landmarks.mp4\", 258)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}